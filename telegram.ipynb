{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMI6a9gYXw9g0+CMyUBiXEY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dinulimann/sentimentele/blob/main/telegram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-telegram-bot\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nest_asyncio\n",
        "import asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTVaHaX-BYTA",
        "outputId": "dfbbd8af-0ae5-41fd-d6b7-d439e6786f4e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-telegram-bot in /usr/local/lib/python3.11/dist-packages (21.10)\n",
            "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.11/dist-packages (from python-telegram-bot) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx~=0.27->python-telegram-bot) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx~=0.27->python-telegram-bot) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "ghqdg1yODpx1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN = '#'"
      ],
      "metadata": {
        "id": "G6FuTxPlDvbj"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBpJ-LdEAUa5",
        "outputId": "ff3f82d5-b566-486a-a480-92a4b879c1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-08 14:56:15--  https://raw.githubusercontent.com/dinulimann/sentimentele/main/model.h5\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1249400 (1.2M) [application/octet-stream]\n",
            "Saving to: ‘model.h5.1’\n",
            "\n",
            "\rmodel.h5.1            0%[                    ]       0  --.-KB/s               \rmodel.h5.1          100%[===================>]   1.19M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-02-08 14:56:15 (18.0 MB/s) - ‘model.h5.1’ saved [1249400/1249400]\n",
            "\n",
            "--2025-02-08 14:56:15--  https://raw.githubusercontent.com/dinulimann/sentimentele/main/tokenizer.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1129915 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘tokenizer.pickle.1’\n",
            "\n",
            "tokenizer.pickle.1  100%[===================>]   1.08M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-02-08 14:56:16 (18.3 MB/s) - ‘tokenizer.pickle.1’ saved [1129915/1129915]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download model (.h5) dan tokenizer (.pickle) dari GitHub\n",
        "!wget https://raw.githubusercontent.com/dinulimann/sentimentele/main/model.h5\n",
        "!wget https://raw.githubusercontent.com/dinulimann/sentimentele/main/tokenizer.pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import pickle\n",
        "\n",
        "# Load model analisis sentimen\n",
        "model = load_model('model.h5')\n",
        "\n",
        "# Load tokenizer\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIJgQfJ9A_zE",
        "outputId": "a70e4cd1-5875-471d-f167-7f8e2bb7d721"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/debugpy/_vendored/pydevd/pydevd.py:1772: RuntimeWarning: coroutine 'Application.shutdown' was never awaited\n",
            "  for int_cmd in cmds_to_add_back:\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.11/dist-packages/debugpy/_vendored/pydevd/pydevd.py:1772: RuntimeWarning: coroutine 'Application.initialize' was never awaited\n",
            "  for int_cmd in cmds_to_add_back:\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    sequence = tokenizer.texts_to_sequences([text])\n",
        "    padded = pad_sequences(sequence, maxlen=100)  # Sesuaikan dengan modelmu\n",
        "    prediction = model.predict(padded)[0][0]\n",
        "    return f\"😊 Positif ({prediction:.2f})\" if prediction > 0.5 else f\"😞 Negatif ({prediction:.2f})\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yflk-Ha9BF9k"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def start(update, context):\n",
        "    await update.message.reply_text('Halo! Kirimkan teks, saya akan menganalisis sentimennya.')\n"
      ],
      "metadata": {
        "id": "-GCuvZrXBP0Y"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def handle_message(update, context):\n",
        "    text = update.message.text\n",
        "    result = predict_sentiment(text)\n",
        "    await update.message.reply_text(result)"
      ],
      "metadata": {
        "id": "cA9KRypgDe1X"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = ApplicationBuilder().token(TOKEN).build()\n",
        "\n",
        "app.add_handler(CommandHandler('start', start))\n",
        "app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))\n",
        "\n",
        "print(\"Bot berjalan...\")\n",
        "await app.run_polling()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T1fahl5DgqH",
        "outputId": "362ce492-14ed-4342-f16d-2eb1768e37a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot berjalan...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n_fngnoCDi-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}